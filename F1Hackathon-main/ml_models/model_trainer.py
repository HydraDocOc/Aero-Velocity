"""Advanced ML Model Trainer with Real Data Integration"""
from typing import Dict, Tuple, Optional
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
from datetime import datetime
import json
from config.settings import MODELS_DIR, ML_RANDOM_STATE, ML_N_ESTIMATORS, ML_LEARNING_RATE, ML_MAX_DEPTH

class ModelTrainer:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_names = ['drag_coefficient', 'cl_front', 'cl_rear', 'front_wing_angle', 
                             'rear_wing_angle', 'ride_height_front', 'ride_height_rear',
                             'track_downforce_level', 'track_corner_count', 'track_length_km']
    
    def train_model_pipeline(self, model_type: str = 'gradient_boosting', use_fastf1_data: bool = False, 
                            n_synthetic_samples: int = 1000) -> Dict:
        print(f"\nTraining {model_type} model with {n_synthetic_samples} samples...")
        X_train, X_test, y_train, y_test = self._prepare_data(n_synthetic_samples)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        model = GradientBoostingRegressor(n_estimators=ML_N_ESTIMATORS, learning_rate=ML_LEARNING_RATE,
                                         max_depth=ML_MAX_DEPTH, random_state=ML_RANDOM_STATE)
        model.fit(X_train_scaled, y_train)
        
        test_pred = model.predict(X_test_scaled)
        rmse = np.sqrt(mean_squared_error(y_test, test_pred))
        r2 = r2_score(y_test, test_pred)
        
        model_path = MODELS_DIR / f'aero_model_{model_type}.joblib'
        scaler_path = MODELS_DIR / f'scaler_{model_type}.joblib'
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        self.models[model_type] = model
        self.scalers[model_type] = scaler
        
        print(f"Model trained. Test RMSE: {rmse:.4f}s, RÂ²: {r2:.4f}")
        print(f"Saved to {model_path}")
        
        return {'model_type': model_type, 'rmse': rmse, 'r2': r2, 'samples': n_synthetic_samples}
    
    def _prepare_data(self, n_samples: int) -> Tuple:
        X, y = self._generate_synthetic_data(n_samples)
        return train_test_split(X, y, test_size=0.2, random_state=ML_RANDOM_STATE)
    
    def _generate_synthetic_data(self, n_samples: int) -> Tuple:
        np.random.seed(ML_RANDOM_STATE)
        X = np.zeros((n_samples, 10))
        X[:, 0] = np.random.uniform(0.65, 0.75, n_samples)  # Cd
        X[:, 1] = np.random.uniform(1.0, 1.8, n_samples)    # CL front
        X[:, 2] = np.random.uniform(1.5, 2.5, n_samples)    # CL rear
        X[:, 3] = np.random.uniform(15, 35, n_samples)      # Front wing
        X[:, 4] = np.random.uniform(18, 38, n_samples)      # Rear wing
        X[:, 5] = np.random.uniform(8, 18, n_samples)       # Ride height front
        X[:, 6] = np.random.uniform(10, 20, n_samples)      # Ride height rear
        X[:, 7] = np.random.choice([0, 1, 2], n_samples)    # Track DF level
        X[:, 8] = np.random.randint(10, 28, n_samples)      # Corners
        X[:, 9] = np.random.uniform(3.3, 7.0, n_samples)    # Track length
        
        y = self._physics_laptime(X) + np.random.normal(0, 0.3, n_samples)
        return X, y
    
    def _physics_laptime(self, X: np.ndarray) -> np.ndarray:
        cd, cl_front, cl_rear = X[:, 0], X[:, 1], X[:, 2]
        track_length, corners = X[:, 9], X[:, 8]
        base_time = (track_length * 1000) / 55.6
        drag_penalty = (cd - 0.70) * 20
        downforce_benefit = -((cl_front + cl_rear) - 3.5) * 5
        corner_time = corners * 0.3
        return np.clip(base_time + drag_penalty + downforce_benefit + corner_time, 60, 120)